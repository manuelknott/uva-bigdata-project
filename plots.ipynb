{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_results = pd.read_csv(\"experiment_results/1_offline_results.txt\", delimiter=\" \", header=None)\n",
    "offline_results.columns = [\"acc\", \"f1\", \"time\"]\n",
    "offline_results.index = offline_results.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_results = pd.read_csv(\"experiment_results/1_online_results.txt\", delimiter=\" \", header=None)\n",
    "online_results.columns = [\"acc\", \"f1\", \"time\"]\n",
    "online_results.index = online_results.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(offline_results[\"acc\"], c=\"blue\", label=\"offline accuracy\")\n",
    "plt.plot(offline_results[\"f1\"], c=\"lightblue\", label=\"offline f1score\")\n",
    "plt.plot(online_results[\"acc\"], c=\"red\", label=\"online accuracy\")\n",
    "plt.plot(online_results[\"f1\"], c=\"lightcoral\", label=\"online f1score\")\n",
    "plt.axvline(x=7.5, ymin=0, ymax=1, c=\"black\", linestyle=\"--\", label=\"class distribution change\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xticks(offline_results.index)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Metric scores\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"experiment_results/1_scores.pdf\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(offline_results[\"time\"], c=\"blue\", label=\"offline fitting time\")\n",
    "plt.plot(online_results[\"time\"], c=\"red\", label=\"online partial fitting time\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xticks(offline_results.index)\n",
    "plt.xlabel(\"Evaluation iterations\")\n",
    "plt.ylabel(\"time [s]\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"experiment_results/1_resources.pdf\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_results = pd.read_csv(\"experiment_results/2_offline_results.txt\", delimiter=\" \", header=None)\n",
    "offline_results.columns = [\"acc\", \"f1\", \"time\"]\n",
    "offline_results[\"memory\"] = [16.66, 15.68, 14.7, 14.945, 17.395, 15.68, 18.62, 19.11, 15.19, 15.68, 18.62, 15.68, 16.415, 17.395, 17.64 ] # from memory log files\n",
    "offline_results.index = offline_results.index + 1\n",
    "offline_results;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_results = pd.read_csv(\"experiment_results/2_online_results.txt\", delimiter=\" \", header=None)\n",
    "online_results.columns = [\"acc\", \"f1\", \"time\"]\n",
    "online_results[\"memory\"] = [35.1, 38.21, 43.42, 43.64, 47.85, 52.07, 55.28, 57.5, 60.71, 64.92, 68.14, 70.35, 71.57, 76.78, 79.8] # from memory log files\n",
    "online_results.index = online_results.index + 1\n",
    "online_results;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(offline_results[\"acc\"], c=\"blue\", label=\"offline accuracy\")\n",
    "plt.plot(offline_results[\"f1\"], c=\"lightblue\", label=\"offline f1score\")\n",
    "plt.plot(online_results[\"acc\"], c=\"red\", label=\"online accuracy\")\n",
    "plt.plot(online_results[\"f1\"], c=\"lightcoral\", label=\"online f1score\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xticks(offline_results.index)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Metric scores\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"experiment_results/2_scores.pdf\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# ax1.set_xlabel(x_label)\n",
    "ax1.set_ylabel(\"time [s]\")\n",
    "ax1.plot(offline_results[\"time\"], c=\"blue\", label=\"offline fitting time\")\n",
    "ax1.plot(online_results[\"time\"], c=\"red\",  label=\"online partial fitting time\")\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel(\"memory [GB]\")\n",
    "ax2.plot(offline_results[\"memory\"], c=\"lightblue\", label=\"offline memory consumption\")\n",
    "ax2.plot(online_results[\"memory\"], c=\"lightcoral\",  label=\"online memory consumption\")\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "handles, labels = [(a + b) for a, b in zip(ax1.get_legend_handles_labels(), ax2.get_legend_handles_labels())]\n",
    "plt.legend(handles, labels, loc='upper left')\n",
    "plt.xticks(offline_results.index)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"experiment_results/2_resources.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
